{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicker \n",
    "from copy import deepcopy\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Clicker:\n",
    "    def __init__(\n",
    "        self,\n",
    "        gt_mask=None,\n",
    "        init_clicks=None,\n",
    "        ignore_label=-1,\n",
    "        click_indx_offset=0,\n",
    "    ):\n",
    "        self.click_indx_offset = click_indx_offset\n",
    "        if gt_mask is not None:\n",
    "            self.__gt_mask = gt_mask == 1\n",
    "            self.not_ignore_mask = gt_mask != ignore_label\n",
    "        else:\n",
    "            self.__gt_mask = None\n",
    "\n",
    "        self.reset_clicks()\n",
    "\n",
    "        if init_clicks is not None:\n",
    "            for click in init_clicks:\n",
    "                self.add_click(click)\n",
    "\n",
    "    def make_next_click(self, pred_mask):\n",
    "        assert self.__gt_mask is not None\n",
    "        click = self._get_next_click(pred_mask)\n",
    "        self.add_click(click)\n",
    "\n",
    "    def get_clicks(self, clicks_limit=None):\n",
    "        return self.clicks_list[:clicks_limit]\n",
    "\n",
    "    def _get_next_click(self, pred_mask, padding=True):\n",
    "        fn_mask = self.__gt_mask & ~pred_mask & self.not_ignore_mask\n",
    "        fp_mask = ~self.__gt_mask & pred_mask & self.not_ignore_mask\n",
    "\n",
    "        if padding:\n",
    "            fn_mask = np.pad(fn_mask, ((1, 1), (1, 1)), \"constant\")\n",
    "            fp_mask = np.pad(fp_mask, ((1, 1), (1, 1)), \"constant\")\n",
    "\n",
    "        fn_mask_dt = cv2.distanceTransform(fn_mask.astype(np.uint8), cv2.DIST_L2, 0)\n",
    "        fp_mask_dt = cv2.distanceTransform(fp_mask.astype(np.uint8), cv2.DIST_L2, 0)\n",
    "\n",
    "        if padding:\n",
    "            fn_mask_dt = fn_mask_dt[1:-1, 1:-1]\n",
    "            fp_mask_dt = fp_mask_dt[1:-1, 1:-1]\n",
    "\n",
    "        fn_mask_dt = fn_mask_dt * self.not_clicked_map\n",
    "        fp_mask_dt = fp_mask_dt * self.not_clicked_map\n",
    "\n",
    "        fn_max_dist = np.max(fn_mask_dt)\n",
    "        fp_max_dist = np.max(fp_mask_dt)\n",
    "\n",
    "        is_positive = fn_max_dist > fp_max_dist\n",
    "        if is_positive:\n",
    "            coords_y, coords_x = np.where(fn_mask_dt == fn_max_dist)  # coords is [y, x]\n",
    "        else:\n",
    "            coords_y, coords_x = np.where(fp_mask_dt == fp_max_dist)  # coords is [y, x]\n",
    "\n",
    "        return Click(is_positive=is_positive, coords=(coords_y[0], coords_x[0]))\n",
    "\n",
    "    def add_click(self, click):\n",
    "        coords = click.coords\n",
    "\n",
    "        click.indx = self.click_indx_offset + self.num_pos_clicks + self.num_neg_clicks\n",
    "        if click.is_positive:\n",
    "            self.num_pos_clicks += 1\n",
    "        else:\n",
    "            self.num_neg_clicks += 1\n",
    "\n",
    "        self.clicks_list.append(click)\n",
    "        if self.__gt_mask is not None:\n",
    "            self.not_clicked_map[coords[0], coords[1]] = False\n",
    "\n",
    "    def _remove_last_click(self):\n",
    "        click = self.clicks_list.pop()\n",
    "        coords = click.coords\n",
    "\n",
    "        if click.is_positive:\n",
    "            self.num_pos_clicks -= 1\n",
    "        else:\n",
    "            self.num_neg_clicks -= 1\n",
    "\n",
    "        if self.__gt_mask is not None:\n",
    "            self.not_clicked_map[coords[0], coords[1]] = True\n",
    "\n",
    "    def reset_clicks(self):\n",
    "        if self.__gt_mask is not None:\n",
    "            self.not_clicked_map = np.ones_like(self.__gt_mask, dtype=bool)\n",
    "\n",
    "        self.num_pos_clicks = 0\n",
    "        self.num_neg_clicks = 0\n",
    "\n",
    "        self.clicks_list = []\n",
    "\n",
    "    def get_state(self):\n",
    "        return deepcopy(self.clicks_list)\n",
    "\n",
    "    def set_state(self, state):\n",
    "        self.reset_clicks()\n",
    "        for click in state:\n",
    "            self.add_click(click)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.clicks_list)\n",
    "\n",
    "\n",
    "class Click:\n",
    "    def __init__(self, is_positive, coords, indx=None):\n",
    "        self.is_positive = is_positive\n",
    "        self.coords = coords\n",
    "        self.indx = indx\n",
    "\n",
    "    @property\n",
    "    def coords_and_indx(self):\n",
    "        return (*self.coords, self.indx)\n",
    "\n",
    "    def copy(self, **kwargs):\n",
    "        self_copy = deepcopy(self)\n",
    "        for k, v in kwargs.items():\n",
    "            setattr(self_copy, k, v)\n",
    "        return self_copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datasets\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "class ISDataset(torch.utils.data.dataset.Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        augmentator=None,\n",
    "        points_sampler=MultiPointSampler(max_num_points=24),\n",
    "        min_object_area=1000,\n",
    "        epoch_len=-1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.epoch_len = epoch_len\n",
    "        self.augmentator = augmentator\n",
    "        self.min_object_area = min_object_area\n",
    "        self.points_sampler = points_sampler\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "\n",
    "        self.dataset_samples = None\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.epoch_len > 0:\n",
    "            index = random.randrange(0, len(self.dataset_samples))\n",
    "\n",
    "        sample = self.get_sample(index)\n",
    "        sample = self.augment_sample(sample)\n",
    "        sample.remove_small_objects(self.min_object_area)\n",
    "\n",
    "        self.points_sampler.sample_object(sample)\n",
    "        points = np.array(self.points_sampler.sample_points())\n",
    "        mask = self.points_sampler.selected_mask\n",
    "\n",
    "        output = {\n",
    "            \"images\": self.to_tensor(sample.image),\n",
    "            \"points\": points.astype(np.float32),\n",
    "            \"instances\": mask,\n",
    "        }\n",
    "\n",
    "        return output\n",
    "\n",
    "    def augment_sample(self, sample) -> DSample:\n",
    "        if self.augmentator is None:\n",
    "            return sample\n",
    "        sample.augment(self.augmentator)\n",
    "        return sample\n",
    "\n",
    "    def get_sample(self, index) -> DSample:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.epoch_len > 0:\n",
    "            return self.epoch_len\n",
    "        return self.get_samples_number()\n",
    "\n",
    "    def get_samples_number(self):\n",
    "        return len(self.dataset_samples)\n",
    "\n",
    "\n",
    "class TestDataset(ISDataset):\n",
    "    def __init__(self, images=None, masks=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self._images_path = Path(images)\n",
    "        self._insts_path = Path(masks)\n",
    "\n",
    "        self.dataset_samples = [x.name for x in sorted(self._images_path.glob(\"*.*\"))]\n",
    "        self._masks_paths = {x.stem: x for x in self._insts_path.glob(\"*.*\")}\n",
    "\n",
    "    def get_sample(self, index) -> DSample:\n",
    "        image_name = self.dataset_samples[index]\n",
    "        image_path = str(self._images_path / image_name)\n",
    "        mask_path = str(self._masks_paths[image_name.split(\".\")[0]])\n",
    "\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        instances_mask = np.max(cv2.imread(mask_path).astype(np.int32), axis=2)\n",
    "        instances_mask[instances_mask > 0] = 1\n",
    "\n",
    "        return DSample(\n",
    "            image,\n",
    "            instances_mask,\n",
    "            objects_ids=[1],\n",
    "            sample_id=index,\n",
    "            imname=image_name,\n",
    "        )\n",
    "\n",
    "\n",
    "class CocoLvisDataset(ISDataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset_path,\n",
    "        split=\"train\",\n",
    "        stuff_prob=0.0,\n",
    "        allow_list_name=None,\n",
    "        anno_file=\"hannotation.pickle\",\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        dataset_path = Path(dataset_path)\n",
    "        self._split_path = dataset_path / split\n",
    "        self.split = split\n",
    "        self._images_path = self._split_path / \"images\"\n",
    "        self._masks_path = self._split_path / \"masks\"\n",
    "        self.stuff_prob = stuff_prob\n",
    "\n",
    "        with open(self._split_path / anno_file, \"rb\") as f:\n",
    "            self.dataset_samples = sorted(pickle.load(f).items())\n",
    "\n",
    "        if allow_list_name is not None:\n",
    "            allow_list_path = self._split_path / allow_list_name\n",
    "            with open(allow_list_path, \"r\") as f:\n",
    "                allow_images_ids = json.load(f)\n",
    "            allow_images_ids = set(allow_images_ids)\n",
    "\n",
    "            self.dataset_samples = [\n",
    "                sample\n",
    "                for sample in self.dataset_samples\n",
    "                if sample[0] in allow_images_ids\n",
    "            ]\n",
    "\n",
    "    def get_sample(self, index) -> DSample:\n",
    "        image_id, sample = self.dataset_samples[index]\n",
    "        image_path = self._images_path / f\"{image_id}.jpg\"\n",
    "\n",
    "        image = cv2.imread(str(image_path))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        packed_masks_path = self._masks_path / f\"{image_id}.pickle\"\n",
    "        with open(packed_masks_path, \"rb\") as f:\n",
    "            encoded_layers, objs_mapping = pickle.load(f)\n",
    "        layers = [cv2.imdecode(x, cv2.IMREAD_UNCHANGED) for x in encoded_layers]\n",
    "        layers = np.stack(layers, axis=2)\n",
    "\n",
    "        instances_info = deepcopy(sample[\"hierarchy\"])\n",
    "        for inst_id, inst_info in list(instances_info.items()):\n",
    "            if inst_info is None:\n",
    "                inst_info = {\"children\": [], \"parent\": None, \"node_level\": 0}\n",
    "                instances_info[inst_id] = inst_info\n",
    "            inst_info[\"mapping\"] = objs_mapping[inst_id]\n",
    "\n",
    "        if self.stuff_prob > 0 and random.random() < self.stuff_prob:\n",
    "            for inst_id in range(sample[\"num_instance_masks\"], len(objs_mapping)):\n",
    "                instances_info[inst_id] = {\n",
    "                    \"mapping\": objs_mapping[inst_id],\n",
    "                    \"parent\": None,\n",
    "                    \"children\": [],\n",
    "                }\n",
    "        else:\n",
    "            for inst_id in range(sample[\"num_instance_masks\"], len(objs_mapping)):\n",
    "                layer_indx, mask_id = objs_mapping[inst_id]\n",
    "                layers[:, :, layer_indx][layers[:, :, layer_indx] == mask_id] = 0\n",
    "\n",
    "        return DSample(image, layers, objects=instances_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# misc\n",
    "from functools import lru_cache\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "def get_dims_with_exclusion(dim, exclude=None):\n",
    "    dims = list(range(dim))\n",
    "    if exclude is not None:\n",
    "        dims.remove(exclude)\n",
    "\n",
    "    return dims\n",
    "\n",
    "\n",
    "def save_checkpoint(net, checkpoints_path, epoch=None):\n",
    "    if epoch is None:\n",
    "        checkpoint_name = \"last_checkpoint.pt\"\n",
    "    else:\n",
    "        checkpoint_name = f\"{epoch:03d}.pt\"\n",
    "\n",
    "    if not checkpoints_path.exists():\n",
    "        checkpoints_path.mkdir(parents=True)\n",
    "\n",
    "    checkpoint_path = checkpoints_path / checkpoint_name\n",
    "    print(f\"Save checkpoint to {str(checkpoint_path)}\")\n",
    "\n",
    "    torch.save({\"state_dict\": net.state_dict()}, str(checkpoint_path))\n",
    "\n",
    "\n",
    "def get_bbox_from_mask(mask):\n",
    "    rows = np.any(mask, axis=1)\n",
    "    cols = np.any(mask, axis=0)\n",
    "    rmin, rmax = np.where(rows)[0][[0, -1]]\n",
    "    cmin, cmax = np.where(cols)[0][[0, -1]]\n",
    "\n",
    "    return rmin, rmax, cmin, cmax\n",
    "\n",
    "\n",
    "def expand_bbox(bbox, expand_ratio, min_crop_size=None):\n",
    "    rmin, rmax, cmin, cmax = bbox\n",
    "    rcenter = 0.5 * (rmin + rmax)\n",
    "    ccenter = 0.5 * (cmin + cmax)\n",
    "    height = expand_ratio * (rmax - rmin + 1)\n",
    "    width = expand_ratio * (cmax - cmin + 1)\n",
    "    if min_crop_size is not None:\n",
    "        height = max(height, min_crop_size)\n",
    "        width = max(width, min_crop_size)\n",
    "\n",
    "    rmin = int(round(rcenter - 0.5 * height))\n",
    "    rmax = int(round(rcenter + 0.5 * height))\n",
    "    cmin = int(round(ccenter - 0.5 * width))\n",
    "    cmax = int(round(ccenter + 0.5 * width))\n",
    "\n",
    "    return rmin, rmax, cmin, cmax\n",
    "\n",
    "\n",
    "def clamp_bbox(bbox, rmin, rmax, cmin, cmax):\n",
    "    return (\n",
    "        max(rmin, bbox[0]),\n",
    "        min(rmax, bbox[1]),\n",
    "        max(cmin, bbox[2]),\n",
    "        min(cmax, bbox[3]),\n",
    "    )\n",
    "\n",
    "\n",
    "def get_bbox_iou(b1, b2):\n",
    "    h_iou = get_segments_iou(b1[:2], b2[:2])\n",
    "    w_iou = get_segments_iou(b1[2:4], b2[2:4])\n",
    "    return h_iou * w_iou\n",
    "\n",
    "\n",
    "def get_segments_iou(s1, s2):\n",
    "    a, b = s1\n",
    "    c, d = s2\n",
    "    intersection = max(0, min(b, d) - max(a, c) + 1)\n",
    "    union = max(1e-6, max(b, d) - min(a, c) + 1)\n",
    "    return intersection / union\n",
    "\n",
    "\n",
    "def get_labels_with_sizes(x):\n",
    "    obj_sizes = np.bincount(x.flatten())\n",
    "    labels = np.nonzero(obj_sizes)[0].tolist()\n",
    "    labels = [x for x in labels if x != 0]\n",
    "    return labels, obj_sizes[labels].tolist()\n",
    "\n",
    "\n",
    "@lru_cache(maxsize=16)\n",
    "def get_palette(num_cls):\n",
    "    palette = np.zeros(3 * num_cls, dtype=np.int32)\n",
    "\n",
    "    for j in range(0, num_cls):\n",
    "        lab = j\n",
    "        i = 0\n",
    "\n",
    "        while lab > 0:\n",
    "            palette[j * 3 + 0] |= ((lab >> 0) & 1) << (7 - i)\n",
    "            palette[j * 3 + 1] |= ((lab >> 1) & 1) << (7 - i)\n",
    "            palette[j * 3 + 2] |= ((lab >> 2) & 1) << (7 - i)\n",
    "            i = i + 1\n",
    "            lab >>= 3\n",
    "\n",
    "    return palette.reshape((-1, 3))\n",
    "\n",
    "\n",
    "def draw_probmap(x):\n",
    "    return cv2.applyColorMap((x * 255).astype(np.uint8), cv2.COLORMAP_HOT)\n",
    "\n",
    "\n",
    "def draw_points(image, points, color, radius=3):\n",
    "    image = image.copy()\n",
    "    for p in points:\n",
    "        if p[0] < 0:\n",
    "            continue\n",
    "        if len(p) == 3:\n",
    "            pradius = {0: 8, 1: 6, 2: 4}[p[2]] if p[2] < 3 else 2\n",
    "        else:\n",
    "            pradius = radius\n",
    "        image = cv2.circle(image, (int(p[1]), int(p[0])), pradius, color, -1)\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def draw_with_blend_and_clicks(\n",
    "    img,\n",
    "    mask=None,\n",
    "    alpha=0.6,\n",
    "    clicks_list=None,\n",
    "    pos_color=(0, 255, 0),\n",
    "    neg_color=(255, 0, 0),\n",
    "    radius=4,\n",
    "):\n",
    "    result = img.copy()\n",
    "\n",
    "    if mask is not None:\n",
    "        palette = get_palette(np.max(mask) + 1)\n",
    "        rgb_mask = palette[mask.astype(np.uint8)]\n",
    "\n",
    "        mask_region = (mask > 0).astype(np.uint8)\n",
    "        result = (\n",
    "            result * (1 - mask_region[:, :, np.newaxis])\n",
    "            + (1 - alpha) * mask_region[:, :, np.newaxis] * result\n",
    "            + alpha * rgb_mask\n",
    "        )\n",
    "        result = result.astype(np.uint8)\n",
    "\n",
    "        # result = (result * (1 - alpha) + alpha * rgb_mask).astype(np.uint8)\n",
    "\n",
    "    if clicks_list is not None and len(clicks_list) > 0:\n",
    "        pos_points = [click.coords for click in clicks_list if click.is_positive]\n",
    "        neg_points = [click.coords for click in clicks_list if not click.is_positive]\n",
    "\n",
    "        result = draw_points(result, pos_points, pos_color, radius=radius)\n",
    "        result = draw_points(result, neg_points, neg_color, radius=radius)\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample \n",
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class DSample:\n",
    "    def __init__(\n",
    "        self,\n",
    "        image,\n",
    "        encoded_masks,\n",
    "        objects=None,\n",
    "        objects_ids=None,\n",
    "        ignore_ids=None,\n",
    "        sample_id=None,\n",
    "        imname=None,\n",
    "    ):\n",
    "        self.image = image\n",
    "        self.sample_id = sample_id\n",
    "        self.imname = imname\n",
    "        if len(encoded_masks.shape) == 2:\n",
    "            encoded_masks = encoded_masks[:, :, np.newaxis]\n",
    "        self._encoded_masks = encoded_masks\n",
    "        self._ignored_regions = []\n",
    "\n",
    "        if objects_ids is not None:\n",
    "            if not objects_ids or not isinstance(objects_ids[0], tuple):\n",
    "                assert encoded_masks.shape[2] == 1\n",
    "                objects_ids = [(0, obj_id) for obj_id in objects_ids]\n",
    "\n",
    "            self._objects = {}\n",
    "            for indx, obj_mapping in enumerate(objects_ids):\n",
    "                self._objects[indx] = {\n",
    "                    \"parent\": None,\n",
    "                    \"mapping\": obj_mapping,\n",
    "                    \"children\": [],\n",
    "                }\n",
    "\n",
    "            if ignore_ids:\n",
    "                if isinstance(ignore_ids[0], tuple):\n",
    "                    self._ignored_regions = ignore_ids\n",
    "                else:\n",
    "                    self._ignored_regions = [(0, region_id) for region_id in ignore_ids]\n",
    "        else:\n",
    "            self._objects = deepcopy(objects)\n",
    "\n",
    "        self._augmented = False\n",
    "        self._soft_mask_aug = None\n",
    "        self._original_data = self.image, self._encoded_masks, deepcopy(self._objects)\n",
    "\n",
    "    def augment(self, augmentator):\n",
    "        self.reset_augmentation()\n",
    "        aug_output = augmentator(image=self.image, mask=self._encoded_masks)\n",
    "        self.image = aug_output[\"image\"]\n",
    "        self._encoded_masks = aug_output[\"mask\"]\n",
    "        self._compute_objects_areas()\n",
    "        self.remove_small_objects(min_area=1)\n",
    "        self._augmented = True\n",
    "\n",
    "    def reset_augmentation(self):\n",
    "        if not self._augmented:\n",
    "            return\n",
    "        orig_image, orig_masks, orig_objects = self._original_data\n",
    "        self.image = orig_image\n",
    "        self._encoded_masks = orig_masks\n",
    "        self._objects = deepcopy(orig_objects)\n",
    "        self._augmented = False\n",
    "        self._soft_mask_aug = None\n",
    "\n",
    "    def remove_small_objects(self, min_area):\n",
    "        if self._objects and not \"area\" in list(self._objects.values())[0]:\n",
    "            self._compute_objects_areas()\n",
    "\n",
    "        for obj_id, obj_info in list(self._objects.items()):\n",
    "            if obj_info[\"area\"] < min_area:\n",
    "                self._remove_object(obj_id)\n",
    "\n",
    "    def get_object_mask(self, obj_id):\n",
    "        layer_indx, mask_id = self._objects[obj_id][\"mapping\"]\n",
    "        obj_mask = (self._encoded_masks[:, :, layer_indx] == mask_id).astype(np.int32)\n",
    "        if self._ignored_regions:\n",
    "            for layer_indx, mask_id in self._ignored_regions:\n",
    "                ignore_mask = self._encoded_masks[:, :, layer_indx] == mask_id\n",
    "                obj_mask[ignore_mask] = -1\n",
    "\n",
    "        return obj_mask\n",
    "\n",
    "    def get_soft_object_mask(self, obj_id):\n",
    "        assert self._soft_mask_aug is not None\n",
    "        original_encoded_masks = self._original_data[1]\n",
    "        layer_indx, mask_id = self._objects[obj_id][\"mapping\"]\n",
    "        obj_mask = (original_encoded_masks[:, :, layer_indx] == mask_id).astype(\n",
    "            np.float32,\n",
    "        )\n",
    "        obj_mask = self._soft_mask_aug(image=obj_mask, mask=original_encoded_masks)[\n",
    "            \"image\"\n",
    "        ]\n",
    "        return np.clip(obj_mask, 0, 1)\n",
    "\n",
    "    def get_background_mask(self):\n",
    "        return np.max(self._encoded_masks, axis=2) == 0\n",
    "\n",
    "    @property\n",
    "    def objects_ids(self):\n",
    "        return list(self._objects.keys())\n",
    "\n",
    "    @property\n",
    "    def gt_mask(self):\n",
    "        assert len(self._objects) == 1\n",
    "        return self.get_object_mask(self.objects_ids[0])\n",
    "\n",
    "    @property\n",
    "    def root_objects(self):\n",
    "        return [\n",
    "            obj_id\n",
    "            for obj_id, obj_info in self._objects.items()\n",
    "            if obj_info[\"parent\"] is None\n",
    "        ]\n",
    "\n",
    "    def _compute_objects_areas(self):\n",
    "        inverse_index = {\n",
    "            node[\"mapping\"]: node_id for node_id, node in self._objects.items()\n",
    "        }\n",
    "        ignored_regions_keys = set(self._ignored_regions)\n",
    "\n",
    "        for layer_indx in range(self._encoded_masks.shape[2]):\n",
    "            objects_ids, objects_areas = get_labels_with_sizes(\n",
    "                self._encoded_masks[:, :, layer_indx],\n",
    "            )\n",
    "            for obj_id, obj_area in zip(objects_ids, objects_areas):\n",
    "                inv_key = (layer_indx, obj_id)\n",
    "                if inv_key in ignored_regions_keys:\n",
    "                    continue\n",
    "                try:\n",
    "                    self._objects[inverse_index[inv_key]][\"area\"] = obj_area\n",
    "                    del inverse_index[inv_key]\n",
    "                except KeyError:\n",
    "                    layer = self._encoded_masks[:, :, layer_indx]\n",
    "                    layer[layer == obj_id] = 0\n",
    "                    self._encoded_masks[:, :, layer_indx] = layer\n",
    "\n",
    "        for obj_id in inverse_index.values():\n",
    "            self._objects[obj_id][\"area\"] = 0\n",
    "\n",
    "    def _remove_object(self, obj_id):\n",
    "        obj_info = self._objects[obj_id]\n",
    "        obj_parent = obj_info[\"parent\"]\n",
    "        for child_id in obj_info[\"children\"]:\n",
    "            self._objects[child_id][\"parent\"] = obj_parent\n",
    "\n",
    "        if obj_parent is not None:\n",
    "            parent_children = self._objects[obj_parent][\"children\"]\n",
    "            parent_children = [x for x in parent_children if x != obj_id]\n",
    "            self._objects[obj_parent][\"children\"] = (\n",
    "                parent_children + obj_info[\"children\"]\n",
    "            )\n",
    "\n",
    "        del self._objects[obj_id]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._objects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# poins sampler\n",
    "import math\n",
    "import random\n",
    "from functools import lru_cache\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class MultiPointSampler:\n",
    "    def __init__(\n",
    "        self,\n",
    "        max_num_points,\n",
    "        prob_gamma=0.7,\n",
    "        expand_ratio=0.1,\n",
    "        positive_erode_prob=0.9,\n",
    "        positive_erode_iters=3,\n",
    "        negative_bg_prob=0.1,\n",
    "        negative_other_prob=0.4,\n",
    "        negative_border_prob=0.5,\n",
    "        merge_objects_prob=0.0,\n",
    "        max_num_merged_objects=2,\n",
    "        use_hierarchy=False,\n",
    "        soft_targets=False,\n",
    "        first_click_center=False,\n",
    "        only_one_first_click=False,\n",
    "        sfc_inner_k=1.7,\n",
    "        sfc_full_inner_prob=0.0,\n",
    "    ):\n",
    "        self._selected_mask = None\n",
    "        self._selected_masks = None\n",
    "        self.max_num_points = max_num_points\n",
    "        self.expand_ratio = expand_ratio\n",
    "        self.positive_erode_prob = positive_erode_prob\n",
    "        self.positive_erode_iters = positive_erode_iters\n",
    "        self.merge_objects_prob = merge_objects_prob\n",
    "        self.use_hierarchy = use_hierarchy\n",
    "        self.soft_targets = soft_targets\n",
    "        self.first_click_center = first_click_center\n",
    "        self.only_one_first_click = only_one_first_click\n",
    "        self.sfc_inner_k = sfc_inner_k\n",
    "        self.sfc_full_inner_prob = sfc_full_inner_prob\n",
    "\n",
    "        if max_num_merged_objects == -1:\n",
    "            max_num_merged_objects = max_num_points\n",
    "        self.max_num_merged_objects = max_num_merged_objects\n",
    "\n",
    "        self.neg_strategies = [\"bg\", \"other\", \"border\"]\n",
    "        self.neg_strategies_prob = [\n",
    "            negative_bg_prob,\n",
    "            negative_other_prob,\n",
    "            negative_border_prob,\n",
    "        ]\n",
    "        assert math.isclose(sum(self.neg_strategies_prob), 1.0)\n",
    "\n",
    "        self._pos_probs = generate_probs(max_num_points, gamma=prob_gamma)\n",
    "        self._neg_probs = generate_probs(max_num_points + 1, gamma=prob_gamma)\n",
    "        self._neg_masks = None\n",
    "\n",
    "    @property\n",
    "    def selected_mask(self):\n",
    "        assert self._selected_mask is not None\n",
    "        return self._selected_mask\n",
    "\n",
    "    @selected_mask.setter\n",
    "    def selected_mask(self, mask):\n",
    "        self._selected_mask = mask[np.newaxis, :].astype(np.float32)\n",
    "\n",
    "    def sample_object(self, sample: DSample):\n",
    "        if len(sample) == 0:\n",
    "            bg_mask = sample.get_background_mask()\n",
    "            self.selected_mask = np.zeros_like(bg_mask, dtype=np.float32)\n",
    "            self._selected_masks = [[]]\n",
    "            self._neg_masks = {strategy: bg_mask for strategy in self.neg_strategies}\n",
    "            self._neg_masks[\"required\"] = []\n",
    "            return\n",
    "\n",
    "        gt_mask, pos_masks, neg_masks = self._sample_mask(sample)\n",
    "        binary_gt_mask = gt_mask > 0.5 if self.soft_targets else gt_mask > 0\n",
    "\n",
    "        self.selected_mask = gt_mask\n",
    "        self._selected_masks = pos_masks\n",
    "\n",
    "        neg_mask_bg = ~binary_gt_mask\n",
    "        neg_mask_border = self._get_border_mask(binary_gt_mask)\n",
    "        if len(sample) <= len(self._selected_masks):\n",
    "            neg_mask_other = neg_mask_bg\n",
    "        else:\n",
    "            neg_mask_other = ~(sample.get_background_mask() | binary_gt_mask)\n",
    "\n",
    "        self._neg_masks = {\n",
    "            \"bg\": neg_mask_bg,\n",
    "            \"other\": neg_mask_other,\n",
    "            \"border\": neg_mask_border,\n",
    "            \"required\": neg_masks,\n",
    "        }\n",
    "\n",
    "    def _sample_mask(self, sample: DSample):\n",
    "        root_obj_ids = sample.root_objects\n",
    "\n",
    "        if len(root_obj_ids) > 1 and random.random() < self.merge_objects_prob:\n",
    "            max_selected_objects = min(len(root_obj_ids), self.max_num_merged_objects)\n",
    "            num_selected_objects = np.random.randint(2, max_selected_objects + 1)\n",
    "            random_ids = random.sample(root_obj_ids, num_selected_objects)\n",
    "        else:\n",
    "            random_ids = [random.choice(root_obj_ids)]\n",
    "\n",
    "        gt_mask = None\n",
    "        pos_segments = []\n",
    "        neg_segments = []\n",
    "        for obj_id in random_ids:\n",
    "            (\n",
    "                obj_gt_mask,\n",
    "                obj_pos_segments,\n",
    "                obj_neg_segments,\n",
    "            ) = self._sample_from_masks_layer(obj_id, sample)\n",
    "            if gt_mask is None:\n",
    "                gt_mask = obj_gt_mask\n",
    "            else:\n",
    "                gt_mask = np.maximum(gt_mask, obj_gt_mask)\n",
    "\n",
    "            pos_segments.extend(obj_pos_segments)\n",
    "            neg_segments.extend(obj_neg_segments)\n",
    "\n",
    "        pos_masks = [self._positive_erode(x) for x in pos_segments]\n",
    "        neg_masks = [self._positive_erode(x) for x in neg_segments]\n",
    "\n",
    "        return gt_mask, pos_masks, neg_masks\n",
    "\n",
    "    def _sample_from_masks_layer(self, obj_id, sample: DSample):\n",
    "        objs_tree = sample._objects\n",
    "\n",
    "        if not self.use_hierarchy:\n",
    "            node_mask = sample.get_object_mask(obj_id)\n",
    "            gt_mask = (\n",
    "                sample.get_soft_object_mask(obj_id) if self.soft_targets else node_mask\n",
    "            )\n",
    "            return gt_mask, [node_mask], []\n",
    "\n",
    "        def _select_node(node_id):\n",
    "            node_info = objs_tree[node_id]\n",
    "            if not node_info[\"children\"] or random.random() < 0.5:\n",
    "                return node_id\n",
    "            return _select_node(random.choice(node_info[\"children\"]))\n",
    "\n",
    "        selected_node = _select_node(obj_id)\n",
    "        node_info = objs_tree[selected_node]\n",
    "        node_mask = sample.get_object_mask(selected_node)\n",
    "        gt_mask = (\n",
    "            sample.get_soft_object_mask(selected_node)\n",
    "            if self.soft_targets\n",
    "            else node_mask\n",
    "        )\n",
    "        pos_mask = node_mask.copy()\n",
    "\n",
    "        negative_segments = []\n",
    "        if node_info[\"parent\"] is not None and node_info[\"parent\"] in objs_tree:\n",
    "            parent_mask = sample.get_object_mask(node_info[\"parent\"])\n",
    "            negative_segments.append(parent_mask & ~node_mask)\n",
    "\n",
    "        for child_id in node_info[\"children\"]:\n",
    "            if objs_tree[child_id][\"area\"] / node_info[\"area\"] < 0.10:\n",
    "                child_mask = sample.get_object_mask(child_id)\n",
    "                pos_mask = pos_mask & ~child_mask\n",
    "\n",
    "        if node_info[\"children\"]:\n",
    "            max_disabled_children = min(len(node_info[\"children\"]), 3)\n",
    "            num_disabled_children = np.random.randint(0, max_disabled_children + 1)\n",
    "            disabled_children = random.sample(\n",
    "                node_info[\"children\"],\n",
    "                num_disabled_children,\n",
    "            )\n",
    "\n",
    "            for child_id in disabled_children:\n",
    "                child_mask = sample.get_object_mask(child_id)\n",
    "                pos_mask = pos_mask & ~child_mask\n",
    "                if self.soft_targets:\n",
    "                    soft_child_mask = sample.get_soft_object_mask(child_id)\n",
    "                    gt_mask = np.minimum(gt_mask, 1.0 - soft_child_mask)\n",
    "                else:\n",
    "                    gt_mask = gt_mask & ~child_mask\n",
    "                negative_segments.append(child_mask)\n",
    "\n",
    "        return gt_mask, [pos_mask], negative_segments\n",
    "\n",
    "    def sample_points(self):\n",
    "        assert self._selected_mask is not None\n",
    "        pos_points = self._multi_mask_sample_points(\n",
    "            self._selected_masks,\n",
    "            is_negative=[False] * len(self._selected_masks),\n",
    "            with_first_click=self.first_click_center,\n",
    "        )\n",
    "\n",
    "        neg_strategy = [\n",
    "            (self._neg_masks[k], prob)\n",
    "            for k, prob in zip(self.neg_strategies, self.neg_strategies_prob)\n",
    "        ]\n",
    "        neg_masks = self._neg_masks[\"required\"] + [neg_strategy]\n",
    "        neg_points = self._multi_mask_sample_points(\n",
    "            neg_masks,\n",
    "            is_negative=[False] * len(self._neg_masks[\"required\"]) + [True],\n",
    "        )\n",
    "\n",
    "        return pos_points + neg_points\n",
    "\n",
    "    def _multi_mask_sample_points(\n",
    "        self,\n",
    "        selected_masks,\n",
    "        is_negative,\n",
    "        with_first_click=False,\n",
    "    ):\n",
    "        selected_masks = selected_masks[: self.max_num_points]\n",
    "\n",
    "        each_obj_points = [\n",
    "            self._sample_points(\n",
    "                mask,\n",
    "                is_negative=is_negative[i],\n",
    "                with_first_click=with_first_click,\n",
    "            )\n",
    "            for i, mask in enumerate(selected_masks)\n",
    "        ]\n",
    "        each_obj_points = [x for x in each_obj_points if len(x) > 0]\n",
    "\n",
    "        points = []\n",
    "        if len(each_obj_points) == 1:\n",
    "            points = each_obj_points[0]\n",
    "        elif len(each_obj_points) > 1:\n",
    "            if self.only_one_first_click:\n",
    "                each_obj_points = each_obj_points[:1]\n",
    "\n",
    "            points = [obj_points[0] for obj_points in each_obj_points]\n",
    "\n",
    "            aggregated_masks_with_prob = []\n",
    "            for x in selected_masks:\n",
    "                if (\n",
    "                    isinstance(x, (list, tuple))\n",
    "                    and x\n",
    "                    and isinstance(x[0], (list, tuple))\n",
    "                ):\n",
    "                    for t, prob in x:\n",
    "                        aggregated_masks_with_prob.append(\n",
    "                            (t, prob / len(selected_masks)),\n",
    "                        )\n",
    "                else:\n",
    "                    aggregated_masks_with_prob.append((x, 1.0 / len(selected_masks)))\n",
    "\n",
    "            other_points_union = self._sample_points(\n",
    "                aggregated_masks_with_prob,\n",
    "                is_negative=True,\n",
    "            )\n",
    "            if len(other_points_union) + len(points) <= self.max_num_points:\n",
    "                points.extend(other_points_union)\n",
    "            else:\n",
    "                points.extend(\n",
    "                    random.sample(\n",
    "                        other_points_union,\n",
    "                        self.max_num_points - len(points),\n",
    "                    ),\n",
    "                )\n",
    "\n",
    "        if len(points) < self.max_num_points:\n",
    "            points.extend([(-1, -1, -1)] * (self.max_num_points - len(points)))\n",
    "\n",
    "        return points\n",
    "\n",
    "    def _sample_points(self, mask, is_negative=False, with_first_click=False):\n",
    "        if is_negative:\n",
    "            num_points = np.random.choice(\n",
    "                np.arange(self.max_num_points + 1),\n",
    "                p=self._neg_probs,\n",
    "            )\n",
    "        else:\n",
    "            num_points = 1 + np.random.choice(\n",
    "                np.arange(self.max_num_points),\n",
    "                p=self._pos_probs,\n",
    "            )\n",
    "\n",
    "        indices_probs = None\n",
    "        if isinstance(mask, (list, tuple)):\n",
    "            indices_probs = [x[1] for x in mask]\n",
    "            indices = [(np.argwhere(x), prob) for x, prob in mask]\n",
    "            if indices_probs:\n",
    "                assert math.isclose(sum(indices_probs), 1.0)\n",
    "        else:\n",
    "            indices = np.argwhere(mask)\n",
    "\n",
    "        points = []\n",
    "        for j in range(num_points):\n",
    "            first_click = with_first_click and j == 0 and indices_probs is None\n",
    "\n",
    "            if first_click:\n",
    "                point_indices = get_point_candidates(\n",
    "                    mask,\n",
    "                    k=self.sfc_inner_k,\n",
    "                    full_prob=self.sfc_full_inner_prob,\n",
    "                )\n",
    "            elif indices_probs:\n",
    "                point_indices_indx = np.random.choice(\n",
    "                    np.arange(len(indices)),\n",
    "                    p=indices_probs,\n",
    "                )\n",
    "                point_indices = indices[point_indices_indx][0]\n",
    "            else:\n",
    "                point_indices = indices\n",
    "\n",
    "            num_indices = len(point_indices)\n",
    "            if num_indices > 0:\n",
    "                point_indx = 0 if first_click else 100\n",
    "                click = point_indices[np.random.randint(0, num_indices)].tolist() + [\n",
    "                    point_indx,\n",
    "                ]\n",
    "                points.append(click)\n",
    "\n",
    "        return points\n",
    "\n",
    "    def _positive_erode(self, mask):\n",
    "        if random.random() > self.positive_erode_prob:\n",
    "            return mask\n",
    "\n",
    "        kernel = np.ones((3, 3), np.uint8)\n",
    "        eroded_mask = cv2.erode(\n",
    "            mask.astype(np.uint8),\n",
    "            kernel,\n",
    "            iterations=self.positive_erode_iters,\n",
    "        ).astype(bool)\n",
    "\n",
    "        if eroded_mask.sum() > 10:\n",
    "            return eroded_mask\n",
    "        return mask\n",
    "\n",
    "    def _get_border_mask(self, mask):\n",
    "        expand_r = int(np.ceil(self.expand_ratio * np.sqrt(mask.sum())))\n",
    "        kernel = np.ones((3, 3), np.uint8)\n",
    "        expanded_mask = cv2.dilate(mask.astype(np.uint8), kernel, iterations=expand_r)\n",
    "        expanded_mask[mask.astype(bool)] = 0\n",
    "        return expanded_mask\n",
    "\n",
    "\n",
    "@lru_cache(maxsize=None)\n",
    "def generate_probs(max_num_points, gamma):\n",
    "    probs = []\n",
    "    last_value = 1\n",
    "    for _ in range(max_num_points):\n",
    "        probs.append(last_value)\n",
    "        last_value *= gamma\n",
    "\n",
    "    probs = np.array(probs)\n",
    "    probs /= probs.sum()\n",
    "\n",
    "    return probs\n",
    "\n",
    "\n",
    "def get_point_candidates(obj_mask, k=1.7, full_prob=0.0):\n",
    "    if full_prob > 0 and random.random() < full_prob:\n",
    "        return obj_mask\n",
    "\n",
    "    padded_mask = np.pad(obj_mask, ((1, 1), (1, 1)), \"constant\")\n",
    "\n",
    "    dt = cv2.distanceTransform(padded_mask.astype(np.uint8), cv2.DIST_L2, 0)[1:-1, 1:-1]\n",
    "    if k > 0:\n",
    "        inner_mask = dt > dt.max() / k\n",
    "        return np.argwhere(inner_mask)\n",
    "\n",
    "    prob_map = dt.flatten()\n",
    "    prob_map /= max(prob_map.sum(), 1e-6)\n",
    "    click_indx = np.random.choice(len(prob_map), p=prob_map)\n",
    "    click_coords = np.unravel_index(click_indx, dt.shape)\n",
    "    return np.array([click_coords])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "from types import SimpleNamespace\n",
    "\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from albumentations import Compose, DualTransform, PadIfNeeded, RandomCrop\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.models.mobilenetv3 import MobileNet_V3_Large_Weights\n",
    "from torchvision.models.segmentation import deeplabv3_mobilenet_v3_large\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class ISModel(nn.Module):\n",
    "    # Your model should not have required parameters for init\n",
    "    def __init__(\n",
    "        self,\n",
    "        pretrained=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.normalization = BatchImageNormalize(\n",
    "            [0.485, 0.456, 0.406],\n",
    "            [0.229, 0.224, 0.225],\n",
    "        )\n",
    "\n",
    "        # Positive, Negative and Previous Mask\n",
    "        self.coord_feature_ch = 3\n",
    "        self.dist_maps = DistMaps(\n",
    "            norm_radius=5,\n",
    "            spatial_scale=1.0,\n",
    "            use_disks=True,\n",
    "        )\n",
    "\n",
    "        weights = MobileNet_V3_Large_Weights.IMAGENET1K_V1 if pretrained else None\n",
    "        self.feature_extractor = deeplabv3_mobilenet_v3_large(\n",
    "            num_classes=1,\n",
    "            weights_backbone=weights,\n",
    "        )\n",
    "\n",
    "        # Add user clicks and mask on input\n",
    "        old_conv = self.feature_extractor.backbone[\"0\"][0]\n",
    "\n",
    "        new_conv = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                old_conv.in_channels + self.coord_feature_ch,\n",
    "                old_conv.out_channels,\n",
    "                kernel_size=1,\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.BatchNorm2d(old_conv.out_channels),\n",
    "            nn.LeakyReLU(negative_slope=0.2),\n",
    "            nn.Conv2d(\n",
    "                old_conv.out_channels,\n",
    "                old_conv.out_channels,\n",
    "                kernel_size=(3, 3),\n",
    "                stride=(2, 2),\n",
    "                padding=(1, 1),\n",
    "                bias=False,\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        self.feature_extractor.backbone[\"0\"][0] = new_conv\n",
    "\n",
    "        # Remove Dropout layer\n",
    "        self.feature_extractor.classifier[0].project[3] = nn.Identity()\n",
    "\n",
    "        # Will be used in testing\n",
    "        self.pred_thr = 0.5\n",
    "\n",
    "    def forward(self, image, points):\n",
    "        image, prev_mask = self.prepare_input(image)\n",
    "        coord_features = self.get_coord_features(image, prev_mask, points)\n",
    "        outputs = self.backbone_forward(image, coord_features)\n",
    "        return outputs\n",
    "\n",
    "    def prepare_input(self, image):\n",
    "        prev_mask = image[:, 3:, :, :]\n",
    "        image = image[:, :3, :, :]\n",
    "        image = self.normalization(image)\n",
    "        return image, prev_mask\n",
    "\n",
    "    def backbone_forward(self, image, coord_features):\n",
    "        net_input = torch.cat((image, coord_features), dim=1)\n",
    "        net_outputs = self.feature_extractor(net_input)[\"out\"]\n",
    "        return {\"instances\": net_outputs}\n",
    "\n",
    "    def get_coord_features(self, image, prev_mask, points):\n",
    "        coord_features = self.dist_maps(image, points)\n",
    "        coord_features = torch.cat((prev_mask, coord_features), dim=1)\n",
    "        return coord_features\n",
    "\n",
    "    def restore_from_checkpoint(self, checkpoint_path, device):\n",
    "        checkpoint = torch.load(checkpoint_path, weights_only=True, map_location=device)\n",
    "        self.load_state_dict(checkpoint[\"state_dict\"])\n",
    "        return self\n",
    "\n",
    "\n",
    "class Predictor:\n",
    "    def __init__(self, model, device):\n",
    "        self.original_image = None\n",
    "        self.device = device\n",
    "        self.prev_prediction = None\n",
    "        self.net = model\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "\n",
    "    def set_input_image(self, image):\n",
    "        image_nd = self.to_tensor(image)\n",
    "        self.original_image = image_nd.to(self.device)\n",
    "        if len(self.original_image.shape) == 3:\n",
    "            self.original_image = self.original_image.unsqueeze(0)\n",
    "        self.prev_prediction = torch.zeros_like(self.original_image[:, :1, :, :])\n",
    "\n",
    "    def get_prediction(self, clicker, prev_mask=None):\n",
    "        clicks_list = deepcopy(clicker.get_clicks())\n",
    "\n",
    "        input_image = self.original_image\n",
    "        if prev_mask is None:\n",
    "            prev_mask = self.prev_prediction\n",
    "\n",
    "        input_image = torch.cat((input_image, prev_mask), dim=1)\n",
    "\n",
    "        prev_size = input_image.shape[2:]\n",
    "        input_image = torch.nn.functional.interpolate(\n",
    "            input_image,\n",
    "            (400, 400),\n",
    "            mode=\"bilinear\",\n",
    "            align_corners=True,\n",
    "        )\n",
    "\n",
    "        # Scale clicks too\n",
    "        for click in clicks_list:\n",
    "            click.coords = (\n",
    "                click.coords[0] / (prev_size[0] / 400.0),\n",
    "                click.coords[1] / (prev_size[1] / 400.0),\n",
    "            )\n",
    "\n",
    "        prediction = self._get_prediction(input_image, [clicks_list])\n",
    "        prediction = torch.nn.functional.interpolate(\n",
    "            prediction,\n",
    "            prev_size,\n",
    "            mode=\"bilinear\",\n",
    "            align_corners=True,\n",
    "        )\n",
    "        prediction = torch.sigmoid(prediction)\n",
    "\n",
    "        self.prev_prediction = prediction\n",
    "        return prediction.cpu().numpy()[0, 0]\n",
    "\n",
    "    def _get_prediction(self, image_nd, clicks_lists):\n",
    "        points_nd = self.get_points_nd(clicks_lists)\n",
    "        return self.net(image_nd, points_nd)[\"instances\"]\n",
    "\n",
    "    def get_points_nd(self, clicks_lists):\n",
    "        total_clicks = []\n",
    "        num_pos_clicks = [\n",
    "            sum(click.is_positive for click in clicks_list)\n",
    "            for clicks_list in clicks_lists\n",
    "        ]\n",
    "        num_neg_clicks = [\n",
    "            len(clicks_list) - num_pos\n",
    "            for clicks_list, num_pos in zip(clicks_lists, num_pos_clicks)\n",
    "        ]\n",
    "        num_max_points = max(num_pos_clicks + num_neg_clicks)\n",
    "        num_max_points = max(1, num_max_points)\n",
    "\n",
    "        for clicks_list in clicks_lists:\n",
    "            neg_clicks, pos_clicks = targets = [], []\n",
    "            for click in clicks_list:\n",
    "                targets[click.is_positive].append(click.coords_and_indx)\n",
    "\n",
    "            pos_padding = num_max_points - len(pos_clicks)\n",
    "            pos_clicks = pos_clicks + pos_padding * [(-1, -1, -1)]\n",
    "\n",
    "            neg_padding = num_max_points - len(neg_clicks)\n",
    "            neg_clicks = neg_clicks + neg_padding * [(-1, -1, -1)]\n",
    "\n",
    "            total_clicks.append(pos_clicks + neg_clicks)\n",
    "\n",
    "        return torch.tensor(total_clicks, device=self.device)\n",
    "\n",
    "\n",
    "class DistMaps(torch.nn.Module):\n",
    "    def __init__(self, norm_radius=5, spatial_scale=1.0, use_disks=True):\n",
    "        super().__init__()\n",
    "        self.spatial_scale = spatial_scale\n",
    "        self.norm_radius = norm_radius\n",
    "        self.use_disks = use_disks\n",
    "\n",
    "    def get_coord_features(self, points, rows, cols):\n",
    "        num_points = points.shape[1] // 2\n",
    "        points = points.view(-1, points.size(2))\n",
    "        points, _ = torch.split(points, [2, 1], dim=1)\n",
    "\n",
    "        invalid_points = torch.max(points, dim=1, keepdim=False)[0] < 0\n",
    "        row_array = torch.arange(\n",
    "            start=0,\n",
    "            end=rows,\n",
    "            step=1,\n",
    "            dtype=torch.float32,\n",
    "            device=points.device,\n",
    "        )\n",
    "        col_array = torch.arange(\n",
    "            start=0,\n",
    "            end=cols,\n",
    "            step=1,\n",
    "            dtype=torch.float32,\n",
    "            device=points.device,\n",
    "        )\n",
    "\n",
    "        coord_rows, coord_cols = torch.meshgrid(\n",
    "            row_array,\n",
    "            col_array,\n",
    "            indexing=\"ij\",\n",
    "        )\n",
    "        coords = torch.stack((coord_rows, coord_cols), dim=0)\n",
    "        coords = coords.unsqueeze(0).repeat(points.size(0), 1, 1, 1)\n",
    "\n",
    "        add_xy = points * self.spatial_scale\n",
    "        add_xy = add_xy.view(points.size(0), points.size(1), 1, 1)\n",
    "        coords.add_(-add_xy)\n",
    "        if not self.use_disks:\n",
    "            coords.div_(self.norm_radius * self.spatial_scale)\n",
    "        coords.mul_(coords)\n",
    "\n",
    "        coords[:, 0] += coords[:, 1]\n",
    "        coords = coords[:, :1]\n",
    "\n",
    "        coords[invalid_points, :, :, :] = 1e6\n",
    "\n",
    "        coords = coords.view(-1, num_points, 1, rows, cols)\n",
    "        coords = coords.min(dim=1)[0]  # -> (bs * num_masks * 2) x 1 x h x w\n",
    "        coords = coords.view(-1, 2, rows, cols)\n",
    "\n",
    "        if self.use_disks:\n",
    "            coords = (coords <= (self.norm_radius * self.spatial_scale) ** 2).float()\n",
    "        else:\n",
    "            coords.sqrt_().mul_(2).tanh_()\n",
    "\n",
    "        return coords\n",
    "\n",
    "    def forward(self, x, coords):\n",
    "        return self.get_coord_features(coords, x.shape[2], x.shape[3])\n",
    "\n",
    "\n",
    "class BatchImageNormalize:\n",
    "    def __init__(self, mean, std, dtype=torch.float):\n",
    "        self.mean = torch.as_tensor(mean, dtype=dtype)[None, :, None, None]\n",
    "        self.std = torch.as_tensor(std, dtype=dtype)[None, :, None, None]\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        tensor = tensor.clone()\n",
    "\n",
    "        tensor.sub_(self.mean.to(tensor.device))\n",
    "        tensor.div_(self.std.to(tensor.device))\n",
    "        return tensor\n",
    "\n",
    "\n",
    "def get_next_points(pred, gt, points, click_indx, pred_thresh=0.5):\n",
    "    \"\"\"Simulate click to the area with largest error\"\"\"\n",
    "    assert click_indx > 0\n",
    "    pred = pred.cpu().numpy()[:, 0, :, :]\n",
    "    gt = gt.cpu().numpy()[:, 0, :, :] > 0.5\n",
    "\n",
    "    fn_mask = gt & (pred < pred_thresh)\n",
    "    fp_mask = ~gt & (pred > pred_thresh)\n",
    "\n",
    "    fn_mask = np.pad(fn_mask, ((0, 0), (1, 1), (1, 1)), \"constant\").astype(np.uint8)\n",
    "    fp_mask = np.pad(fp_mask, ((0, 0), (1, 1), (1, 1)), \"constant\").astype(np.uint8)\n",
    "    num_points = points.size(1) // 2\n",
    "    points = points.clone()\n",
    "\n",
    "    for bindx in range(fn_mask.shape[0]):\n",
    "        fn_mask_dt = cv2.distanceTransform(fn_mask[bindx], cv2.DIST_L2, 5)[1:-1, 1:-1]\n",
    "        fp_mask_dt = cv2.distanceTransform(fp_mask[bindx], cv2.DIST_L2, 5)[1:-1, 1:-1]\n",
    "\n",
    "        fn_max_dist = np.max(fn_mask_dt)\n",
    "        fp_max_dist = np.max(fp_mask_dt)\n",
    "\n",
    "        is_positive = fn_max_dist > fp_max_dist\n",
    "        dt = fn_mask_dt if is_positive else fp_mask_dt\n",
    "        inner_mask = dt > max(fn_max_dist, fp_max_dist) / 2.0\n",
    "        indices = np.argwhere(inner_mask)\n",
    "        if len(indices) > 0:\n",
    "            coords = indices[np.random.randint(0, len(indices))]\n",
    "            if is_positive:\n",
    "                points[bindx, num_points - click_indx, 0] = float(coords[0])\n",
    "                points[bindx, num_points - click_indx, 1] = float(coords[1])\n",
    "                points[bindx, num_points - click_indx, 2] = float(click_indx)\n",
    "            else:\n",
    "                points[bindx, 2 * num_points - click_indx, 0] = float(coords[0])\n",
    "                points[bindx, 2 * num_points - click_indx, 1] = float(coords[1])\n",
    "                points[bindx, 2 * num_points - click_indx, 2] = float(click_indx)\n",
    "\n",
    "    return points\n",
    "\n",
    "\n",
    "class ISTrainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        cfg,\n",
    "        instance_loss,\n",
    "        trainset,\n",
    "        valset,\n",
    "        image_dump_interval=10,\n",
    "        checkpoint_interval=10,\n",
    "        max_initial_points=0,\n",
    "        max_interactive_clicks=0,\n",
    "    ):\n",
    "        self.cfg = cfg\n",
    "        self.max_initial_points = max_initial_points\n",
    "        self.instance_loss = instance_loss\n",
    "        self.max_interactive_clicks = max_interactive_clicks\n",
    "        self.checkpoint_interval = checkpoint_interval\n",
    "        self.image_dump_interval = image_dump_interval\n",
    "        self.trainset = trainset\n",
    "        self.valset = valset\n",
    "\n",
    "        train_size = trainset.get_samples_number()\n",
    "        print(f\"Dataset of {train_size} samples was loaded for training.\")\n",
    "        val_size = valset.get_samples_number()\n",
    "        print(f\"Dataset of {val_size} samples was loaded for validation.\")\n",
    "\n",
    "        self.train_data = DataLoader(\n",
    "            trainset,\n",
    "            batch_size=cfg.batch_size,\n",
    "            shuffle=True,\n",
    "            drop_last=True,\n",
    "            pin_memory=True,\n",
    "            num_workers=4,\n",
    "        )\n",
    "\n",
    "        self.val_data = DataLoader(\n",
    "            valset,\n",
    "            batch_size=cfg.val_batch_size,\n",
    "            shuffle=False,\n",
    "            drop_last=True,\n",
    "            pin_memory=True,\n",
    "            num_workers=4,\n",
    "        )\n",
    "\n",
    "        self.device = cfg.device\n",
    "        self.net = model.to(self.device)\n",
    "        self.optim = torch.optim.AdamW(self.net.parameters(), lr=3e-4)\n",
    "\n",
    "    def run(self, num_epochs, validation=True):\n",
    "        print(f\"Total Epochs: {num_epochs}\")\n",
    "        for epoch in range(num_epochs):\n",
    "            self.training(epoch)\n",
    "            if validation:\n",
    "                self.validation(epoch)\n",
    "\n",
    "    def training(self, epoch):\n",
    "        tbar = tqdm(self.train_data, ncols=100)\n",
    "        self.net.train()\n",
    "        train_loss = 0.0\n",
    "\n",
    "        for i, batch_data in enumerate(tbar):\n",
    "            global_step = epoch * len(self.train_data) + i\n",
    "\n",
    "            loss, splitted_batch_data, outputs = self.batch_forward(batch_data)\n",
    "\n",
    "            self.optim.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optim.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            if (\n",
    "                self.image_dump_interval > 0\n",
    "                and global_step % self.image_dump_interval == 0\n",
    "            ):\n",
    "                self.save_visualization(\n",
    "                    splitted_batch_data,\n",
    "                    outputs,\n",
    "                    global_step,\n",
    "                    prefix=\"train\",\n",
    "                )\n",
    "\n",
    "            tbar.set_description(f\"Epoch {epoch}, training loss {train_loss/(i+1):.4f}\")\n",
    "\n",
    "        save_checkpoint(self.net, self.cfg.CHECKPOINTS_PATH, epoch=None)\n",
    "\n",
    "        if epoch % self.checkpoint_interval == 0:\n",
    "            save_checkpoint(self.net, self.cfg.CHECKPOINTS_PATH, epoch=epoch)\n",
    "\n",
    "    def validation(self, epoch):\n",
    "        tbar = tqdm(self.val_data, ncols=100)\n",
    "        self.net.eval()\n",
    "        val_loss = 0\n",
    "\n",
    "        for i, batch_data in enumerate(tbar):\n",
    "            loss, _, _ = self.batch_forward(\n",
    "                batch_data,\n",
    "                validation=True,\n",
    "            )\n",
    "\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            tbar.set_description(\n",
    "                f\"Epoch {epoch}, validation loss: {val_loss/(i + 1):.4f}\",\n",
    "            )\n",
    "\n",
    "    def batch_forward(self, batch_data, validation=False):\n",
    "        with torch.set_grad_enabled(not validation):\n",
    "            batch_data = {k: v.to(self.device) for k, v in batch_data.items()}\n",
    "            image, gt_mask, points = (\n",
    "                batch_data[\"images\"],\n",
    "                batch_data[\"instances\"],\n",
    "                batch_data[\"points\"],\n",
    "            )\n",
    "\n",
    "            prev_output = torch.zeros_like(image, dtype=torch.float32)[:, :1, :, :]\n",
    "\n",
    "            # Make interactive steps\n",
    "            with torch.no_grad():\n",
    "                num_iters = random.randint(0, self.max_interactive_clicks)\n",
    "\n",
    "                for click_indx in range(num_iters):\n",
    "                    if not validation:\n",
    "                        self.net.eval()\n",
    "\n",
    "                    net_input = torch.cat((image, prev_output), dim=1)\n",
    "                    prev_output = self.net(net_input, points)[\"instances\"]\n",
    "                    prev_output = torch.sigmoid(prev_output)\n",
    "\n",
    "                    points = get_next_points(\n",
    "                        prev_output,\n",
    "                        gt_mask,\n",
    "                        points,\n",
    "                        click_indx + 1,\n",
    "                    )\n",
    "\n",
    "                    if not validation:\n",
    "                        self.net.train()\n",
    "\n",
    "            batch_data[\"points\"] = points\n",
    "\n",
    "            net_input = torch.cat((image, prev_output), dim=1)\n",
    "            output = self.net(net_input, points)\n",
    "\n",
    "            loss = self.instance_loss(output[\"instances\"], batch_data[\"instances\"])\n",
    "            loss = torch.mean(loss)\n",
    "\n",
    "        return loss, batch_data, output\n",
    "\n",
    "    def save_visualization(\n",
    "        self,\n",
    "        splitted_batch_data,\n",
    "        outputs,\n",
    "        global_step,\n",
    "        prefix,\n",
    "    ):\n",
    "        output_images_path = self.cfg.VIS_PATH / prefix\n",
    "\n",
    "        if not output_images_path.exists():\n",
    "            output_images_path.mkdir(parents=True)\n",
    "        image_name_prefix = f\"{global_step:06d}\"\n",
    "\n",
    "        def _save_image(suffix, image):\n",
    "            cv2.imwrite(\n",
    "                str(output_images_path / f\"{image_name_prefix}_{suffix}.jpg\"),\n",
    "                image,\n",
    "                [cv2.IMWRITE_JPEG_QUALITY, 85],\n",
    "            )\n",
    "\n",
    "        images = splitted_batch_data[\"images\"]\n",
    "        points = splitted_batch_data[\"points\"]\n",
    "        instance_masks = splitted_batch_data[\"instances\"]\n",
    "\n",
    "        gt_instance_masks = instance_masks.cpu().numpy()\n",
    "        predicted_instance_masks = (\n",
    "            torch.sigmoid(outputs[\"instances\"]).detach().cpu().numpy()\n",
    "        )\n",
    "        points = points.detach().cpu().numpy()\n",
    "\n",
    "        image_blob, points = images[0], points[0]\n",
    "        gt_mask = np.squeeze(gt_instance_masks[0], axis=0)\n",
    "        predicted_mask = np.squeeze(predicted_instance_masks[0], axis=0)\n",
    "\n",
    "        image = image_blob.cpu().numpy() * 255\n",
    "        image = image.transpose((1, 2, 0))\n",
    "\n",
    "        image_with_points = draw_points(\n",
    "            image,\n",
    "            points[: self.max_initial_points],\n",
    "            (0, 255, 0),\n",
    "        )\n",
    "        image_with_points = draw_points(\n",
    "            image_with_points,\n",
    "            points[self.max_initial_points :],\n",
    "            (0, 0, 255),\n",
    "        )\n",
    "\n",
    "        gt_mask[gt_mask < 0] = 0.25\n",
    "        gt_mask = draw_probmap(gt_mask)\n",
    "        predicted_mask = draw_probmap(predicted_mask)\n",
    "        viz_image = np.hstack((image_with_points, gt_mask, predicted_mask))\n",
    "        viz_image = viz_image.astype(np.uint8)\n",
    "\n",
    "        _save_image(\"instance_segmentation\", viz_image[:, :, ::-1])\n",
    "\n",
    "\n",
    "class UniformRandomResize(DualTransform):\n",
    "    \"\"\"Example of how to implement spatial augmentations.\n",
    "\n",
    "    Note that we need to recalculate click (keypoint) positions!\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        scale_range,\n",
    "        interpolation=cv2.INTER_LINEAR,\n",
    "        always_apply=True,\n",
    "        p=1,\n",
    "    ):\n",
    "        super().__init__(always_apply, p)\n",
    "        self.scale_range = scale_range\n",
    "        self.interpolation = interpolation\n",
    "\n",
    "    def get_params_dependent_on_targets(self, params):\n",
    "        scale = random.uniform(*self.scale_range)\n",
    "        height = int(round(params[\"image\"].shape[0] * scale))\n",
    "        width = int(round(params[\"image\"].shape[1] * scale))\n",
    "        return {\"new_height\": height, \"new_width\": width}\n",
    "\n",
    "    def apply(\n",
    "        self,\n",
    "        img,\n",
    "        new_height=0,\n",
    "        new_width=0,\n",
    "        interpolation=cv2.INTER_LINEAR,\n",
    "        **params,\n",
    "    ):\n",
    "        resize_op = A.augmentations.geometric.resize.Resize(\n",
    "            height=new_height,\n",
    "            width=new_width,\n",
    "            interpolation=interpolation,\n",
    "        )\n",
    "        return resize_op(image=img)[\"image\"]\n",
    "\n",
    "    def apply_to_keypoint(self, keypoint, new_height=0, new_width=0, **params):\n",
    "        scale_x = new_width / params[\"cols\"]\n",
    "        scale_y = new_height / params[\"rows\"]\n",
    "        keypoint = A.augmentations.geometric.functional.keypoint_scale(\n",
    "            keypoint,\n",
    "            scale_x,\n",
    "            scale_y,\n",
    "        )\n",
    "        return keypoint\n",
    "\n",
    "    def apply_to_bbox(self, *_, **__):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def get_transform_init_args_names(self):\n",
    "        return \"scale_range\", \"interpolation\"\n",
    "\n",
    "    @property\n",
    "    def targets_as_params(self):\n",
    "        return [\"image\"]\n",
    "\n",
    "\n",
    "def train_segmentation():\n",
    "    input_size = (400, 400)\n",
    "    model = ISModel(pretrained=True)\n",
    "\n",
    "    cfg = SimpleNamespace()\n",
    "    exp_path = Path(\"./experiments\")\n",
    "    cfg.EXP_PATH = exp_path\n",
    "    cfg.CHECKPOINTS_PATH = exp_path / \"checkpoints\"\n",
    "    cfg.VIS_PATH = exp_path / \"vis\"\n",
    "\n",
    "    cfg.EXP_PATH.mkdir(parents=True, exist_ok=True)\n",
    "    cfg.CHECKPOINTS_PATH.mkdir(exist_ok=True)\n",
    "    cfg.VIS_PATH.mkdir(exist_ok=True)\n",
    "\n",
    "    cfg.device = torch.device(\"cuda\")\n",
    "\n",
    "    cfg.max_initial_points = 24\n",
    "    cfg.batch_size = 48\n",
    "    cfg.val_batch_size = cfg.batch_size\n",
    "\n",
    "    instance_loss = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    # You can add more augmentations here\n",
    "    h, w = input_size\n",
    "    train_augmentator = Compose(\n",
    "        [\n",
    "            UniformRandomResize(scale_range=(0.75, 1.40)),\n",
    "            PadIfNeeded(\n",
    "                min_height=h,\n",
    "                min_width=w,\n",
    "                border_mode=cv2.BORDER_CONSTANT,\n",
    "                value=0,\n",
    "            ),\n",
    "            RandomCrop(*input_size),\n",
    "        ],\n",
    "        p=1.0,\n",
    "    )\n",
    "\n",
    "    val_augmentator = Compose(\n",
    "        [\n",
    "            PadIfNeeded(\n",
    "                min_height=h,\n",
    "                min_width=w,\n",
    "                border_mode=cv2.BORDER_CONSTANT,\n",
    "                value=0,\n",
    "            ),\n",
    "            RandomCrop(*input_size),\n",
    "        ],\n",
    "        p=1.0,\n",
    "    )\n",
    "\n",
    "    points_sampler = MultiPointSampler(\n",
    "        cfg.max_initial_points,\n",
    "        prob_gamma=0.80,\n",
    "        merge_objects_prob=0.15,\n",
    "        max_num_merged_objects=2,\n",
    "    )\n",
    "\n",
    "    trainset = CocoLvisDataset(\n",
    "        \"./COCO_LVIS\",\n",
    "        split=\"train\",\n",
    "        augmentator=train_augmentator,\n",
    "        min_object_area=1000,\n",
    "        points_sampler=points_sampler,\n",
    "        epoch_len=30000,\n",
    "        stuff_prob=0.30,\n",
    "    )\n",
    "\n",
    "    valset = CocoLvisDataset(\n",
    "        \"./COCO_LVIS\",\n",
    "        split=\"val\",\n",
    "        augmentator=val_augmentator,\n",
    "        min_object_area=1000,\n",
    "        points_sampler=points_sampler,\n",
    "        epoch_len=2000,\n",
    "    )\n",
    "\n",
    "    trainer = ISTrainer(\n",
    "        model,\n",
    "        cfg,\n",
    "        instance_loss,\n",
    "        trainset,\n",
    "        valset,\n",
    "        checkpoint_interval=5,\n",
    "        image_dump_interval=1000,\n",
    "        max_initial_points=cfg.max_initial_points,\n",
    "        max_interactive_clicks=3,\n",
    "    )\n",
    "\n",
    "    trainer.run(num_epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/mobilenet_v3_large-8738ca79.pth\" to /tmp/xdg_cache/torch/hub/checkpoints/mobilenet_v3_large-8738ca79.pth\n",
      "100%|██████████| 21.1M/21.1M [00:00<00:00, 63.8MB/s]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'COCO_LVIS/train/hannotation.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5353/3025476425.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_segmentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_5353/1614044656.py\u001b[0m in \u001b[0;36mtrain_segmentation\u001b[0;34m()\u001b[0m\n\u001b[1;32m    625\u001b[0m     )\n\u001b[1;32m    626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m     trainset = CocoLvisDataset(\n\u001b[0m\u001b[1;32m    628\u001b[0m         \u001b[0;34m\"./COCO_LVIS\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_5353/3678976326.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset_path, split, stuff_prob, allow_list_name, anno_file, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstuff_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstuff_prob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_split_path\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0manno_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'COCO_LVIS/train/hannotation.pickle'"
     ]
    }
   ],
   "source": [
    "train_segmentation()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
